{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolving network architectures\n",
    "\n",
    "By [Marcus Ghosh](https://profiles.imperial.ac.uk/m.ghosh/).\n",
    "\n",
    "With inspiration from [NEAT](https://neat-python.readthedocs.io/en/latest/) and [Neuro4ML](https://neuro4ml.github.io/). \n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ghoshm/Evo_tutorial/Evo_tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim\n",
    "\n",
    "We're going to write a simple evolutionary algorithm, and use it to solve a task. \n",
    "\n",
    "There are 3 parts to the exercise - which you should work on in pairs: \n",
    "\n",
    "> 0. Understand the network model. \n",
    "> 1. Write an evolutionary algorithm. \n",
    "> 2. A friendly contest. \n",
    "\n",
    "For the last 5 minutes we'll discuss what worked and how the tutorial could be improved! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "\n",
    "from src import *\n",
    "\n",
    "# For Google Colab\n",
    "if not os.path.exists('Data/test_current.csv'):\n",
    "  !git clone https://github.com/ghoshm/Evo_tutorial.git \n",
    "  %cd /Evo_tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "Our goal is to approximate the [Hodgkin-Huxley model](https://en.wikipedia.org/wiki/Hodgkin%E2%80%93Huxley_model) - which describes how neurons respond to electrical inputs. \n",
    "\n",
    "Specifically, this model translates sequences of continuous values (representing time-varying input currents) into binary vectors (denoting if the model produced an output spike or not at each time step). \n",
    "\n",
    "In *Data* you'll find **train** and **test** sets of: \n",
    " \n",
    "* **Current** - inputs that were provided to the HH model. A numpy array of shape repeats x time which we'll call ```_I```. E.g. ```train_I```. \n",
    "\n",
    "* **Spikes** - contains two numpy vectors which we'll term: \n",
    "    * ```_spike_times``` - the time of each spike from the HH model (in ms).\n",
    "    * ```_spike_idx``` - which repeat each spike comes from. \n",
    "\n",
    "In each data set there are: \n",
    "* **Train** - 100 repeats, with 10,000 time steps each. \n",
    "* **Test** - 50 repeats, with 10,000 time steps each.\n",
    "\n",
    "We'll start by loading the training data. \n",
    "\n",
    "In the interest of time, we'll just focus on the first 200ms (feel free to use more or less data depending on how fast your machine is)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_I = np.loadtxt('Data/train_current.csv') # shape (repeats, num_time_steps)\n",
    "train_spike_times, train_spike_idx = np.loadtxt('Data/train_spikes.csv') # shape (num_spikes,)\n",
    "\n",
    "# Crop \n",
    "time_limit = 200 # in ms\n",
    "train_I = train_I[:, :time_limit*10]\n",
    "train_spike_idx = train_spike_idx[train_spike_times < time_limit]\n",
    "train_spike_times = train_spike_times[train_spike_times < time_limit]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a feel for the data try plotting some input currents and the model's output spikes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.random.randint(low=0, high=train_I.shape[0]) # sample a random repeat\n",
    "HH_spikes = train_spike_times[train_spike_idx == n] # collect HH model spikes \n",
    "\n",
    "plt.plot(np.arange(len(train_I[n])) * 0.1, train_I[n], 'k', alpha=0.25, label=\"Input current\")\n",
    "plt.scatter(HH_spikes, np.ones(len(HH_spikes)), marker=\".\", color=\"xkcd:purple\", label=\"HH model (spikes)\")\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To approximate the HH model, we're going to try to evolve a neural network model.\n",
    "\n",
    "The core of this model will be the ```RecurrentNetwork``` class in src.py. \n",
    "\n",
    "As a start, we'll initialise a model (an instance of the class) with: \n",
    "* 1 input unit - for the current.\n",
    "* 1 hidden unit. \n",
    "* 2 output units.\n",
    "\n",
    "When we pass inputs through the network (i.e. forward through the model), each output unit will acquire a value (or activation). To readout \"spikes\", we'll take an ```argmax``` of these units at each time step.      \n",
    "\n",
    "Note that, for now, our model has no connections / weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = RecurrentNetwork(n_inputs=1, n_hidden=1, n_outputs=2)\n",
    "network.connections "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the ```plot_approximation``` and ```mean_vr_distance``` functions (from src.py) to test our model. \n",
    "\n",
    "With no connections, the model will just guess randomly (spike or no spike) at every time step and perform badly. \n",
    "\n",
    "Below we'll visualise and quantify this:\n",
    "* **Plot** - in response to the same time-varying inputs, our network model (in green) will spike a lot more than the HH model (in purple). \n",
    "\n",
    "* **Metric** - for all of the train samples, we can measure the similarity between our network model's spikes and the HH model's spikes, using a metric known as the [van Rossum distance](http://www.scholarpedia.org/article/Measures_of_spike_train_synchrony). A lower value indicates a better match. For now, our model will have a high value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_approximation(network, train_spike_times, train_spike_idx, train_I)\n",
    "d = mean_vr_distance(network, train_spike_times, train_spike_idx, train_I, disable_reporting=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the ```.add_connections``` and ```.add_nodes``` functions (in ```RecurrentNetwork```) we can add connections and nodes to our network which may or may not improve it's performance.\n",
    "\n",
    "Note: if your model spikes very little (or not at all) the score will be good (as the HH model's output is very sparse).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.add_nodes(1)\n",
    "network.add_connections(5)\n",
    "\n",
    "print(network.connections)\n",
    "\n",
    "plot_approximation(network, train_spike_times, train_spike_idx, train_I)\n",
    "d = mean_vr_distance(network, train_spike_times, train_spike_idx, train_I, disable_reporting=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Task 0. Have a look through the ```RecurrentNetwork``` class in src.py to get a feel for how the model is initialised, how to forward through it and how adding nodes and connections works. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Writing an evolutionary algorithm \n",
    "\n",
    "To optimise our model, we're going to write a simple evolutionary algorithm in 4 steps:\n",
    "\n",
    "* Generate a population of networks \n",
    "* Evaluate each network's fitness \n",
    "* Rank network's by their fitness \n",
    "* Make a new population by varying the best network(s)\n",
    "\n",
    "Then, we'll wrap these steps into a function.\n",
    "\n",
    "> Task 1: Fill in the code below to create a simple evolutionary algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a population of networks\n",
    "population_size = 5 # the number of networks in each generation\n",
    "networks = []\n",
    "for n in range(population_size): \n",
    "    # Fill in code here\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each network's fitness \n",
    "fitness = []\n",
    "for n in range(population_size):\n",
    "    # Fill in code here \n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank network's by their fitness \n",
    "# Fill in code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new population by varying the best network(s)\n",
    "# Fill in code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, wrap all of the above code into a function \n",
    "\n",
    "# I've suggested some inputs and outputs here, but you may want to add others! \n",
    "\n",
    "def evolve_networks(population_size, i_connections, i_nodes, epochs):\n",
    "    \"\"\"\n",
    "    Evolves networks to solve a given task.  \n",
    "    Arguments: \n",
    "        population_size: the number of networks per generation. \n",
    "        i_connections: nodes per network in generation 0. \n",
    "        i_nodes: connections per network in generation 1. \n",
    "        epochs: the number of generations to run. \n",
    "    Outputs: \n",
    "        networks: a list of networks from the final generation. \n",
    "    \"\"\"\n",
    "    # Generate a population of networks \n",
    "    networks = []\n",
    "    for n in range(population_size):\n",
    "        # Fill in code\n",
    "        pass\n",
    "\n",
    "    for _ in tqdm(range(epochs)):\n",
    "        # Evaluate each network's fitness\n",
    "\n",
    "        # Rank networks by their fitness\n",
    "\n",
    "        # Make a new population by varying the best network(s)\n",
    "\n",
    "        pass\n",
    "    \n",
    "    return networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, try testing your function with a small number of epochs\n",
    "\n",
    "# Note: using tqdm as suggested above will allow you to estimate your codes run time\n",
    "    # And save you waiting around.\n",
    "\n",
    "networks = evolve_networks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Contest\n",
    "\n",
    "Now we have our evolutionary algorithm up and running, we'll have a friendly contest to see who can get the best (lowest) test score. \n",
    "\n",
    "To improve your score you could try anything you like! \n",
    "\n",
    "For example you could:\n",
    "* Add new functions, to the RNN class, to vary networks (e.g. alter weights or even activation functions).\n",
    "* Add a bias term to each unit, and functions to vary these. \n",
    "* Speed up the code by writing a more efficient forward pass (using matrix multiplication) - which will allow you to run more generations. \n",
    "\n",
    "Note: not spiking gets a good score, so may end up being a local minimum that is hard to escape. To avoid this, you could alter your fitness function to score models with few or no spikes as inf.\n",
    "\n",
    "> Task 2: Try to evolve the best model by adding functionality to your code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_I = np.loadtxt('Data/test_current.csv') # shape (repeats, num_time_steps)\n",
    "test_spike_times, test_spike_idx = np.loadtxt('Data/test_spikes.csv') # shape (num_spikes,)\n",
    "\n",
    "# Crop \n",
    "test_I = test_I[:, :time_limit*10]\n",
    "test_spike_idx = test_spike_idx[test_spike_times < time_limit]\n",
    "test_spike_times = test_spike_times[test_spike_times < time_limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your model\n",
    "plot_approximation(network, test_spike_times, test_spike_idx, test_I)\n",
    "d = mean_vr_distance(network, test_spike_times, test_spike_idx, test_I, disable_reporting=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Evo_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
